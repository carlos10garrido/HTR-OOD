_target_: src.models.transformers_hf.HTRTransformerLitModule

# Accessing to data in configs/train_htr.yaml
datasets: ${data}
_logger: ${logger}
tokenizer: ${tokenizer}


optimizer:
  _target_: torch.optim.Adam
  _partial_: true
  lr: 0.0002
  # weight_decay: 0.001

scheduler: null
  # _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
  # _partial_: true
  # mode: min
  # factor: 0.1
  # patience: 10

# visualize_attention: False


net: 
  _target_: src.models.components.transformer_kang.TransformerKang
  use_backbone: True
  patch_per_column: True
  image_size: ${data.train.train_config.img_size}
  encoder_layers: 4
  encoder_attention_heads: 8
  encoder_ffn_dim: 512
  patch_size: 1
  # vocab_size: 101
  d_model: 1024
  dropout: 0.1
  decoder_layers: 4
  decoder_attention_heads: 8
  decoder_ffn_dim: 512
  activation_function: 'relu'
  tokenizer: ${tokenizer}

compile: false
